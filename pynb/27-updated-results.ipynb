{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "107cbafd-44e1-42f7-91ce-323fc7aefa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../xrun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e05ac33a-9b50-4d7e-b618-eed9830ac680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from xrun.data.run_info import RunInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b031cb8-40e8-4bad-9099-68276c271e06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_cost_from_file(file_path: Path):\n",
    "    if file_path.exists():\n",
    "            with open(file_path, \"r\") as f:\n",
    "                return float(f.read())\n",
    "    else:\n",
    "        # print(f\"Warning: {file_path} not found!\")\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def get_algorithm_name(run_info):\n",
    "    if run_info.algorithm == \"basic-clustering\":\n",
    "        return \"StreamKM++ (buggy)\"\n",
    "    elif run_info.algorithm == \"sensitivity-sampling\":\n",
    "        return \"Sensitivity Sampling\"\n",
    "    elif run_info.algorithm == \"group-sampling\":\n",
    "        return \"Group Sampling\"\n",
    "    elif run_info.algorithm == \"bico\":\n",
    "        return \"BICO\"\n",
    "    elif run_info.algorithm == \"stream-km++\":\n",
    "        return \"StreamKM++\"\n",
    "    elif run_info.algorithm == \"ray-maker\":\n",
    "        return \"Ray Maker\"\n",
    "    return \"Unknown\"\n",
    "\n",
    "def get_dataset_print_name(run_info):\n",
    "    d = {\n",
    "        \"census\": \"Census\",\n",
    "        \"censuslowd\": \"Census+PCA\",\n",
    "        \"covertype\": \"Covertype\",\n",
    "        \"covertypelowd\": \"Covertype+PCA\",\n",
    "        \"tower\": \"Tower\",\n",
    "        \"hardinstanceb1\": \"Benchmark\",\n",
    "        \"hardinstanceb15\": \"Benchmark-1.5\",\n",
    "        \"hardinstanceb2\": \"Benchmark-2.0\",\n",
    "        \"oldhardinstanceb1\": \"Old Benchmark\",\n",
    "        \"oldhardinstanceb2\": \"Old Benchmark-2.0\",\n",
    "        \"caltech101\": \"Caltech\",\n",
    "        \"caltech101lowd\": \"Caltech+PCA\",\n",
    "        \"oldcaltech101\": \"Old Caltech\",\n",
    "        \"nytimes100d\": \"NYTimes\",\n",
    "        \"nytimespcalowd\": \"NYTimes+PCA\",\n",
    "    }\n",
    "    if run_info.dataset in d:\n",
    "        return d[run_info.dataset]\n",
    "    return run_info.dataset\n",
    "\n",
    "\n",
    "def compute_distortion(real_cost, coreset_cost):\n",
    "    if real_cost is not None and coreset_cost is not None:\n",
    "        return max(float(real_cost/coreset_cost), float(coreset_cost/real_cost))\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_costs(file_paths):\n",
    "    costs = []\n",
    "    for index, run_file_path in enumerate(file_paths):\n",
    "        run_info = RunInfo.load_json(run_file_path)\n",
    "        if \"hardinstance\" in run_info.dataset and run_info.k > 40:\n",
    "            continue\n",
    "        if run_info.algorithm == \"stream-km++\" and run_info.m > 200*run_info.k:\n",
    "            continue\n",
    "        real_cost = load_cost_from_file(run_file_path.parent / \"real_cost.txt\")\n",
    "        coreset_cost = load_cost_from_file(run_file_path.parent / \"coreset_cost.txt\")\n",
    "        real_cost_synthetic = load_cost_from_file(run_file_path.parent / \"real_cost_synthetic.txt\")\n",
    "        coreset_cost_synthetic = load_cost_from_file(run_file_path.parent / \"coreset_cost_synthetic.txt\")\n",
    "        real_cost_synthetic2 = load_cost_from_file(run_file_path.parent / \"real_cost_convexsynthetic.txt\")\n",
    "        coreset_cost_synthetic2 = load_cost_from_file(run_file_path.parent / \"coreset_cost_convexsynthetic.txt\")\n",
    "        distortion = compute_distortion(real_cost, coreset_cost)\n",
    "        distortion_synthetic = compute_distortion(real_cost_synthetic, coreset_cost_synthetic)\n",
    "        distortion_synthetic2 = compute_distortion(real_cost_synthetic2, coreset_cost_synthetic2)\n",
    "        costs.append({\n",
    "            \"dataset\": get_dataset_print_name(run_info),\n",
    "            \"algorithm\": get_algorithm_name(run_info),\n",
    "            \"k\": run_info.k,\n",
    "            \"coreset_size\": run_info.m,\n",
    "            \"coreset_size_factor\": int(run_info.m / run_info.k),\n",
    "            \"running_time\": int(run_info.duration_secs),\n",
    "            \"real_cost\": real_cost,\n",
    "            \"coreset_cost\": coreset_cost,\n",
    "            \"distortion\": distortion,\n",
    "            \"real_cost_synthetic\": real_cost_synthetic,\n",
    "            \"coreset_cost_synthetic\": coreset_cost_synthetic,\n",
    "            \"distortion_synthetic\": distortion_synthetic,\n",
    "            \"real_cost_synthetic2\": real_cost_synthetic2,\n",
    "            \"coreset_cost_synthetic2\": coreset_cost_synthetic2,\n",
    "            \"distortion_synthetic2\": distortion_synthetic2,\n",
    "            # \"run_file_path\": str(run_file_path),\n",
    "        })\n",
    "    df_data = pd.DataFrame(costs)\n",
    "    return df_data.groupby([\"dataset\", \"algorithm\", \"k\", \"coreset_size\"], as_index=False).head(10)\n",
    "    #return df_data\n",
    "\n",
    "def aggregate_costs(df_costs: pd.DataFrame):\n",
    "    group_columns = [\"dataset\", \"algorithm\", \"k\", \"coreset_size\", \"coreset_size_factor\"]\n",
    "    df_top_k = df_costs.groupby(group_columns, as_index=False).head(10)\n",
    "    df_aggr_costs = df_top_k.groupby(group_columns, as_index=False).agg(\n",
    "        experiment_count=(\"algorithm\", \"count\"),\n",
    "        real_cost_mean=(\"real_cost\", \"mean\"),\n",
    "        real_cost_std=(\"real_cost\", \"std\"),\n",
    "        coreset_cost_mean=(\"coreset_cost\", \"mean\"),\n",
    "        coreset_cost_std=(\"coreset_cost\", \"std\"),\n",
    "        running_time_mean=(\"running_time\", \"mean\"),\n",
    "        running_time_std=(\"running_time\", \"std\"),\n",
    "        distortion_mean=(\"distortion\", \"mean\"),\n",
    "        distortion_median=(\"distortion\", \"median\"),\n",
    "        distortion_std=(\"distortion\", \"std\"),\n",
    "        distortion_max=(\"distortion\", \"max\"),\n",
    "        distortion_synthetic_mean=(\"distortion_synthetic\", \"mean\"),\n",
    "        distortion_synthetic_std=(\"distortion_synthetic\", \"std\"),\n",
    "        distortion_synthetic2_mean=(\"distortion_synthetic2\", \"mean\"),\n",
    "        distortion_synthetic2_std=(\"distortion_synthetic2\", \"std\"),\n",
    "    )\n",
    "    df_aggr_costs[\"running_time\"] = pd.to_timedelta(df_aggr_costs.running_time_mean, unit='s')\n",
    "    df_aggr_costs[\"running_time_formatted\"] = df_aggr_costs[\"running_time\"].map(\n",
    "        lambda x: f\"{x.components.hours:02d}h {x.components.minutes:02d}m {x.components.seconds:02d}s\"\n",
    "    )\n",
    "    return df_aggr_costs\n",
    "\n",
    "\n",
    "def display_results_for(df_aggr_costs: pd.DataFrame, dataset_name: str, show_counts: bool=True, show_running_times:bool=True, show_costs: bool=True):\n",
    "    pd.set_option('display.float_format', '{:.2e}'.format)\n",
    "    \n",
    "    display(HTML(f\"<h2 style='border-bottom:solid 1px Black;padding-bottom:5px;'>Results for {dataset_name}</h2>\"))\n",
    "    df_filtered = df_aggr_costs[df_aggr_costs.dataset == dataset_name]\n",
    "    \n",
    "    html_str = \"\"\n",
    "    \n",
    "    if show_counts:\n",
    "        df_counts = pd.pivot_table(df_filtered, values=\"experiment_count\", index=[\"algorithm\"], columns=[\"k\"])\n",
    "        df_counts = df_counts.rename_axis(None, axis=0).rename_axis(None, axis=1)\n",
    "        html_str += f'<div style=\"border:solid 1px White; width:300px;float:left;\">'\n",
    "        html_str += f\"<h4 style='text-align:center;'>Experiment Counts</h4>\"\n",
    "        html_str += df_counts.style.format(precision=0).to_html()\n",
    "        html_str += \"</div>\"\n",
    "    \n",
    "    if show_running_times:\n",
    "        df_run_times = pd.pivot_table(df_filtered, values=\"running_time_formatted\", index=[\"algorithm\"], columns=[\"k\"], aggfunc=lambda x: x)\n",
    "        df_run_times = df_run_times.rename_axis(None, axis=0).rename_axis(None, axis=1)\n",
    "\n",
    "        html_str += f'<div style=\"border:solid 1px White; float:left;\">'\n",
    "        html_str += f\"<h4 style='text-align:center;'>Average Running Times</h4>\"\n",
    "        html_str += df_run_times.to_html()\n",
    "        html_str += \"</div>\"\n",
    "        \n",
    "    display(HTML(html_str))\n",
    "\n",
    "    if show_costs:\n",
    "        df_real_costs = pd.pivot_table(df_filtered, values=\"real_cost_mean\", index=[\"algorithm\"], columns=[\"k\"])\n",
    "        df_real_costs = df_real_costs.rename_axis(None, axis=0).rename_axis(None, axis=1)\n",
    "        \n",
    "        df_coreset_costs = pd.pivot_table(df_filtered, values=\"coreset_cost_mean\", index=[\"algorithm\"], columns=[\"k\"])\n",
    "        df_coreset_costs = df_coreset_costs.rename_axis(None, axis=0).rename_axis(None, axis=1)\n",
    "        \n",
    "        html_str = \"\"\n",
    "        html_str += f'<div style=\"border:solid 1px #eee; float:left;\">'\n",
    "        html_str += f\"<h4 style='text-align:center;'>Real costs</h4>\"\n",
    "        html_str += df_real_costs.to_html()\n",
    "        html_str += \"</div>\"\n",
    "        \n",
    "        html_str += f'<div style=\"border:solid 1px #eee; float:left;\">'\n",
    "        html_str += f\"<h4 style='text-align:center;'>Coreset costs</h4>\"\n",
    "        html_str += df_coreset_costs.to_html()\n",
    "        html_str += \"</div>\"\n",
    "        display(HTML(html_str))\n",
    "    \n",
    "    display(HTML(f'<h4>Distortions</h4>'))\n",
    "    df_distortions = pd.pivot_table(df_filtered, values=\"distortion_max\", index=[\"algorithm\"], columns=[\"k\"])\n",
    "    df_distortions = df_distortions.rename_axis(None, axis=0).rename_axis(None, axis=1)\n",
    "    display(df_distortions)\n",
    "    \n",
    "def add_combined_mean_std(df: pd.DataFrame, attr: str, g_format: bool=False):\n",
    "    def combiner(row) -> str:\n",
    "        mean = row[f\"{attr}_mean\"]\n",
    "        std =  row[f\"{attr}_std\"]\n",
    "        if g_format:\n",
    "            return f\"{mean:.1e} ({std:.1e})\"\n",
    "        else:\n",
    "            return f\"{mean:0.2f} ({std:0.3f})\"\n",
    "    df[f\"{attr}_mean_std\"] = df.apply(lambda x: combiner(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74a656af-33ce-4b43-b21e-0110dc292e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_results_dir = Path(\"../data/experiments-skadi/\")\n",
    "run_files = list(data_results_dir.glob(\"**/*.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "092218ed-9263-4ac3-9967-e0c4df41f88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9445"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(run_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42a89daa-a68c-4023-b03d-0f68b9f19a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_files_filtered = [f for f in run_files if len(list(f.parent.glob(\"*.txt\"))) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb0e3947-d028-4433-b66e-07c2c99fce31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9445"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(run_files_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aeadc0d5-3298-4011-b5dc-d7d892e83e7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cost_data = get_costs(run_files_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11153ca4-948a-42b0-b06a-34d8f40b0bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "include_datasets = [\n",
    "    'Caltech', 'Caltech+PCA', 'Census', 'Census+PCA', 'Covertype', 'Covertype+PCA', \n",
    "    'Tower', 'NYTimes', 'NYTimes+PCA', \n",
    "    # 'Benchmark-1.0', 'Benchmark-1.5', 'Benchmark-2.0',\n",
    "    'Benchmark',\n",
    "]\n",
    "include_algorithms = [\n",
    "    'StreamKM++', 'Group Sampling', 'Ray Maker', 'BICO', 'Sensitivity Sampling', \n",
    "    # 'StreamKM++ (buggy)'\n",
    "]\n",
    "df_cost_filtered = df_cost_data[df_cost_data.algorithm.isin(include_algorithms) & df_cost_data.dataset.isin(include_datasets)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aea17f9e-b9b4-4b28-87d4-f34419ad1851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file_contents(file_path):\n",
    "    with open(file_path) as fp:\n",
    "        return float(fp.read())\n",
    "\n",
    "pca_running_times = {\n",
    "    \"Caltech+PCA\": {\n",
    "        10: load_file_contents(\"../data/input/caltech101-sift.txt.gz-svd-d10-running-time.txt\"),\n",
    "        20: load_file_contents(\"../data/input/caltech101-sift.txt.gz-svd-d20-running-time.txt\"),\n",
    "        30: load_file_contents(\"../data/input/caltech101-sift.txt.gz-svd-d30-running-time.txt\"),\n",
    "        40: load_file_contents(\"../data/input/caltech101-sift.txt.gz-svd-d40-running-time.txt\"),\n",
    "        50: load_file_contents(\"../data/input/caltech101-sift.txt.gz-svd-d50-running-time.txt\"),\n",
    "    },\n",
    "    \"Census+PCA\": {\n",
    "        10: load_file_contents(\"../data/input/USCensus1990.data.txt-svd-d10-running-time.txt\"),\n",
    "        20: load_file_contents(\"../data/input/USCensus1990.data.txt-svd-d20-running-time.txt\"),\n",
    "        30: load_file_contents(\"../data/input/USCensus1990.data.txt-svd-d30-running-time.txt\"),\n",
    "        40: load_file_contents(\"../data/input/USCensus1990.data.txt-svd-d40-running-time.txt\"),\n",
    "        50: load_file_contents(\"../data/input/USCensus1990.data.txt-svd-d50-running-time.txt\"),\n",
    "    },\n",
    "    \"Covertype+PCA\": {\n",
    "        10: load_file_contents(\"../data/input/covtype.data.gz-svd-d10-running-time.txt\"),\n",
    "        20: load_file_contents(\"../data/input/covtype.data.gz-svd-d20-running-time.txt\"),\n",
    "        30: load_file_contents(\"../data/input/covtype.data.gz-svd-d30-running-time.txt\"),\n",
    "        40: load_file_contents(\"../data/input/covtype.data.gz-svd-d40-running-time.txt\"),\n",
    "        50: load_file_contents(\"../data/input/covtype.data.gz-svd-d50-running-time.txt\"),\n",
    "    },\n",
    "    \"Covertype+PCA\": {\n",
    "        10: load_file_contents(\"../data/input/covtype.data.gz-svd-d10-running-time.txt\"),\n",
    "        20: load_file_contents(\"../data/input/covtype.data.gz-svd-d20-running-time.txt\"),\n",
    "        30: load_file_contents(\"../data/input/covtype.data.gz-svd-d30-running-time.txt\"),\n",
    "        40: load_file_contents(\"../data/input/covtype.data.gz-svd-d40-running-time.txt\"),\n",
    "        50: load_file_contents(\"../data/input/covtype.data.gz-svd-d50-running-time.txt\"),\n",
    "    },\n",
    "    \"NYTimes+PCA\": {\n",
    "        10: load_file_contents(\"../data/input/docword.nytimes.txt.gz-svd-d10-running-time.txt\"),\n",
    "        20: load_file_contents(\"../data/input/docword.nytimes.txt.gz-svd-d20-running-time.txt\"),\n",
    "        30: load_file_contents(\"../data/input/docword.nytimes.txt.gz-svd-d30-running-time.txt\"),\n",
    "        40: load_file_contents(\"../data/input/docword.nytimes.txt.gz-svd-d40-running-time.txt\"),\n",
    "        50: load_file_contents(\"../data/input/docword.nytimes.txt.gz-svd-d50-running-time.txt\"),        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a8c3b45-1523-4450-b15b-0fceadea6ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset, runtimes in pca_running_times.items():\n",
    "    for k, running_time in runtimes.items():\n",
    "        df_cost_filtered.loc[(df_cost_filtered.dataset == dataset) & (df_cost_filtered.k == k), \"running_time\"] += running_time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0483562e-3326-4241-a036-8a7b0faafdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cost_filtered.to_csv(\"results-raw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ca1a5d-6b03-48e9-9bdb-7532e5ece416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7498d786-964c-42f9-bb92-06c23049d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggr_costs = aggregate_costs(df_cost_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4adbc24e-27aa-4345-9c40-bf924d4af076",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette(\"tab10\")\n",
    "algorithm_colors = {algo: colors[i] for i, algo in enumerate(df_aggr_costs.algorithm.unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08ecb144-073c-428e-842d-ffb9f338e09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggr_costs[\"k_formatted\"] = \"$k$=\" + df_aggr_costs[\"k\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad2a82-727c-4a62-8984-01f25a5835c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Experiment Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9de5d82a-c281-474d-af15-d1262aed8247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>BICO</th>\n",
       "      <th>Group Sampling</th>\n",
       "      <th>Ray Maker</th>\n",
       "      <th>Sensitivity Sampling</th>\n",
       "      <th>StreamKM++</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>k</th>\n",
       "      <th>coreset_size_factor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Benchmark</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">10</th>\n",
       "      <th>50</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <th>50</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Tower</th>\n",
       "      <th>80</th>\n",
       "      <th>500</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">100</th>\n",
       "      <th>50</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "algorithm                          BICO  Group Sampling  Ray Maker  \\\n",
       "dataset   k   coreset_size_factor                                    \n",
       "Benchmark 10  50                   10.0            10.0       10.0   \n",
       "              100                  10.0            10.0       10.0   \n",
       "              200                  10.0            10.0       10.0   \n",
       "              500                  10.0            10.0       10.0   \n",
       "          20  50                   10.0            10.0       10.0   \n",
       "...                                 ...             ...        ...   \n",
       "Tower     80  500                  10.0            10.0       10.0   \n",
       "          100 50                   10.0            10.0       10.0   \n",
       "              100                  10.0            10.0       10.0   \n",
       "              200                  10.0            10.0       10.0   \n",
       "              500                  10.0            10.0       10.0   \n",
       "\n",
       "algorithm                          Sensitivity Sampling  StreamKM++  \n",
       "dataset   k   coreset_size_factor                                    \n",
       "Benchmark 10  50                                   10.0        10.0  \n",
       "              100                                  10.0        10.0  \n",
       "              200                                  10.0        10.0  \n",
       "              500                                  10.0         NaN  \n",
       "          20  50                                   10.0        10.0  \n",
       "...                                                 ...         ...  \n",
       "Tower     80  500                                  10.0         NaN  \n",
       "          100 50                                   10.0        10.0  \n",
       "              100                                  10.0        10.0  \n",
       "              200                                  10.0        10.0  \n",
       "              500                                  10.0         NaN  \n",
       "\n",
       "[196 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_experiment_counts = pd.pivot_table(\n",
    "    data=df_aggr_costs,\n",
    "    values=\"experiment_count\",\n",
    "    index=[\"dataset\", \"k\", \"coreset_size_factor\"],\n",
    "    columns=[\"algorithm\"],\n",
    ")\n",
    "\n",
    "df_experiment_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "107d725f-9d0b-450e-8c6f-25cd30190ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_experiment_counts.to_excel(\"experiment-counts.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dee4892-45c1-4cf5-8de7-755d76d902b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Distortions (k-means++)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30c8e2ef-69b7-4d87-82c0-ec4b4d681e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>BICO</th>\n",
       "      <th>Group Sampling</th>\n",
       "      <th>Ray Maker</th>\n",
       "      <th>Sensitivity Sampling</th>\n",
       "      <th>StreamKM++</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>k</th>\n",
       "      <th>coreset_size_factor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Benchmark</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">10</th>\n",
       "      <th>50</th>\n",
       "      <td>3.40 (0.440)</td>\n",
       "      <td>1.02 (0.010)</td>\n",
       "      <td>5.05 (0.157)</td>\n",
       "      <td>1.02 (0.005)</td>\n",
       "      <td>1.07 (0.005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3.24 (0.729)</td>\n",
       "      <td>1.01 (0.004)</td>\n",
       "      <td>3.84 (0.081)</td>\n",
       "      <td>1.01 (0.003)</td>\n",
       "      <td>1.05 (0.004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2.90 (0.153)</td>\n",
       "      <td>1.01 (0.002)</td>\n",
       "      <td>3.48 (0.052)</td>\n",
       "      <td>1.01 (0.002)</td>\n",
       "      <td>1.04 (0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>2.62 (0.095)</td>\n",
       "      <td>1.01 (0.001)</td>\n",
       "      <td>3.40 (0.058)</td>\n",
       "      <td>1.00 (0.001)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <th>50</th>\n",
       "      <td>3.22 (0.160)</td>\n",
       "      <td>1.04 (0.004)</td>\n",
       "      <td>5.52 (0.266)</td>\n",
       "      <td>1.02 (0.003)</td>\n",
       "      <td>1.08 (0.006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Tower</th>\n",
       "      <th>80</th>\n",
       "      <th>500</th>\n",
       "      <td>1.02 (0.001)</td>\n",
       "      <td>1.02 (0.003)</td>\n",
       "      <td>1.02 (0.001)</td>\n",
       "      <td>1.01 (0.004)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">100</th>\n",
       "      <th>50</th>\n",
       "      <td>1.19 (0.007)</td>\n",
       "      <td>1.10 (0.009)</td>\n",
       "      <td>1.45 (0.010)</td>\n",
       "      <td>1.03 (0.008)</td>\n",
       "      <td>1.05 (0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.10 (0.008)</td>\n",
       "      <td>1.06 (0.007)</td>\n",
       "      <td>1.12 (0.005)</td>\n",
       "      <td>1.02 (0.007)</td>\n",
       "      <td>1.03 (0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1.04 (0.001)</td>\n",
       "      <td>1.03 (0.005)</td>\n",
       "      <td>1.05 (0.002)</td>\n",
       "      <td>1.01 (0.003)</td>\n",
       "      <td>1.02 (0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>1.01 (0.001)</td>\n",
       "      <td>1.02 (0.003)</td>\n",
       "      <td>1.03 (0.002)</td>\n",
       "      <td>1.01 (0.003)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "algorithm                                  BICO Group Sampling     Ray Maker  \\\n",
       "dataset   k   coreset_size_factor                                              \n",
       "Benchmark 10  50                   3.40 (0.440)   1.02 (0.010)  5.05 (0.157)   \n",
       "              100                  3.24 (0.729)   1.01 (0.004)  3.84 (0.081)   \n",
       "              200                  2.90 (0.153)   1.01 (0.002)  3.48 (0.052)   \n",
       "              500                  2.62 (0.095)   1.01 (0.001)  3.40 (0.058)   \n",
       "          20  50                   3.22 (0.160)   1.04 (0.004)  5.52 (0.266)   \n",
       "...                                         ...            ...           ...   \n",
       "Tower     80  500                  1.02 (0.001)   1.02 (0.003)  1.02 (0.001)   \n",
       "          100 50                   1.19 (0.007)   1.10 (0.009)  1.45 (0.010)   \n",
       "              100                  1.10 (0.008)   1.06 (0.007)  1.12 (0.005)   \n",
       "              200                  1.04 (0.001)   1.03 (0.005)  1.05 (0.002)   \n",
       "              500                  1.01 (0.001)   1.02 (0.003)  1.03 (0.002)   \n",
       "\n",
       "algorithm                         Sensitivity Sampling    StreamKM++  \n",
       "dataset   k   coreset_size_factor                                     \n",
       "Benchmark 10  50                          1.02 (0.005)  1.07 (0.005)  \n",
       "              100                         1.01 (0.003)  1.05 (0.004)  \n",
       "              200                         1.01 (0.002)  1.04 (0.002)  \n",
       "              500                         1.00 (0.001)           NaN  \n",
       "          20  50                          1.02 (0.003)  1.08 (0.006)  \n",
       "...                                                ...           ...  \n",
       "Tower     80  500                         1.01 (0.004)           NaN  \n",
       "          100 50                          1.03 (0.008)  1.05 (0.002)  \n",
       "              100                         1.02 (0.007)  1.03 (0.001)  \n",
       "              200                         1.01 (0.003)  1.02 (0.000)  \n",
       "              500                         1.01 (0.003)           NaN  \n",
       "\n",
       "[196 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_combined_mean_std(df=df_aggr_costs, attr=\"distortion\")\n",
    "\n",
    "df_results_table = pd.pivot_table(\n",
    "    data=df_aggr_costs,\n",
    "    values=\"distortion_mean_std\",\n",
    "    index=[\"dataset\", \"k\", \"coreset_size_factor\"],\n",
    "    columns=[\"algorithm\"],\n",
    "    aggfunc=lambda x: ' '.join(x)\n",
    ")\n",
    "df_results_table.to_excel(\"distortions.xlsx\")\n",
    "df_results_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cb29c8-292c-4b39-ae7e-1301a944b3cf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Distortions (MEB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "747e6216-a45c-4cbd-a333-333ce649d9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>BICO</th>\n",
       "      <th>Group Sampling</th>\n",
       "      <th>Ray Maker</th>\n",
       "      <th>Sensitivity Sampling</th>\n",
       "      <th>StreamKM++</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>k</th>\n",
       "      <th>coreset_size_factor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Benchmark</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">10</th>\n",
       "      <th>50</th>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <th>50</th>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Tower</th>\n",
       "      <th>80</th>\n",
       "      <th>500</th>\n",
       "      <td>1.00 (0.000)</td>\n",
       "      <td>1.03 (0.001)</td>\n",
       "      <td>1.00 (0.000)</td>\n",
       "      <td>1.01 (0.006)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">100</th>\n",
       "      <th>50</th>\n",
       "      <td>1.00 (0.000)</td>\n",
       "      <td>1.03 (0.007)</td>\n",
       "      <td>1.19 (0.015)</td>\n",
       "      <td>1.06 (0.012)</td>\n",
       "      <td>1.00 (0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.00 (0.000)</td>\n",
       "      <td>1.03 (0.006)</td>\n",
       "      <td>1.05 (0.004)</td>\n",
       "      <td>1.04 (0.011)</td>\n",
       "      <td>1.00 (0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1.00 (0.000)</td>\n",
       "      <td>1.03 (0.003)</td>\n",
       "      <td>1.02 (0.002)</td>\n",
       "      <td>1.03 (0.007)</td>\n",
       "      <td>1.00 (0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>1.00 (0.000)</td>\n",
       "      <td>1.03 (0.002)</td>\n",
       "      <td>1.00 (0.000)</td>\n",
       "      <td>1.01 (0.003)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "algorithm                                  BICO Group Sampling     Ray Maker  \\\n",
       "dataset   k   coreset_size_factor                                              \n",
       "Benchmark 10  50                      nan (nan)      nan (nan)     nan (nan)   \n",
       "              100                     nan (nan)      nan (nan)     nan (nan)   \n",
       "              200                     nan (nan)      nan (nan)     nan (nan)   \n",
       "              500                     nan (nan)      nan (nan)     nan (nan)   \n",
       "          20  50                      nan (nan)      nan (nan)     nan (nan)   \n",
       "...                                         ...            ...           ...   \n",
       "Tower     80  500                  1.00 (0.000)   1.03 (0.001)  1.00 (0.000)   \n",
       "          100 50                   1.00 (0.000)   1.03 (0.007)  1.19 (0.015)   \n",
       "              100                  1.00 (0.000)   1.03 (0.006)  1.05 (0.004)   \n",
       "              200                  1.00 (0.000)   1.03 (0.003)  1.02 (0.002)   \n",
       "              500                  1.00 (0.000)   1.03 (0.002)  1.00 (0.000)   \n",
       "\n",
       "algorithm                         Sensitivity Sampling    StreamKM++  \n",
       "dataset   k   coreset_size_factor                                     \n",
       "Benchmark 10  50                             nan (nan)     nan (nan)  \n",
       "              100                            nan (nan)     nan (nan)  \n",
       "              200                            nan (nan)     nan (nan)  \n",
       "              500                            nan (nan)           NaN  \n",
       "          20  50                             nan (nan)     nan (nan)  \n",
       "...                                                ...           ...  \n",
       "Tower     80  500                         1.01 (0.006)           NaN  \n",
       "          100 50                          1.06 (0.012)  1.00 (0.000)  \n",
       "              100                         1.04 (0.011)  1.00 (0.000)  \n",
       "              200                         1.03 (0.007)  1.00 (0.000)  \n",
       "              500                         1.01 (0.003)           NaN  \n",
       "\n",
       "[196 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_combined_mean_std(df=df_aggr_costs, attr=\"distortion_synthetic\")\n",
    "\n",
    "df_results_table = pd.pivot_table(\n",
    "    data=df_aggr_costs,\n",
    "    values=\"distortion_synthetic_mean_std\",\n",
    "    index=[\"dataset\", \"k\", \"coreset_size_factor\"],\n",
    "    columns=[\"algorithm\"],\n",
    "    aggfunc=lambda x: ' '.join(x)\n",
    ")\n",
    "df_results_table.to_excel(\"distortions-meb-clustering.xlsx\")\n",
    "df_results_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899c3d8e-ac42-4aaa-9bf9-e9f50797617e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Distortions (Convex Hull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3c98b69-7d7f-48a3-822b-c41885f570df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>BICO</th>\n",
       "      <th>Group Sampling</th>\n",
       "      <th>Ray Maker</th>\n",
       "      <th>Sensitivity Sampling</th>\n",
       "      <th>StreamKM++</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>k</th>\n",
       "      <th>coreset_size_factor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Benchmark</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">10</th>\n",
       "      <th>50</th>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <th>50</th>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "      <td>nan (nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Tower</th>\n",
       "      <th>80</th>\n",
       "      <th>500</th>\n",
       "      <td>1.00 (0.001)</td>\n",
       "      <td>1.02 (0.005)</td>\n",
       "      <td>1.01 (0.001)</td>\n",
       "      <td>1.02 (0.008)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">100</th>\n",
       "      <th>50</th>\n",
       "      <td>1.04 (0.008)</td>\n",
       "      <td>1.03 (0.016)</td>\n",
       "      <td>1.26 (0.016)</td>\n",
       "      <td>1.08 (0.021)</td>\n",
       "      <td>1.01 (0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.02 (0.003)</td>\n",
       "      <td>1.02 (0.007)</td>\n",
       "      <td>1.07 (0.004)</td>\n",
       "      <td>1.05 (0.014)</td>\n",
       "      <td>1.01 (0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1.01 (0.003)</td>\n",
       "      <td>1.02 (0.008)</td>\n",
       "      <td>1.02 (0.003)</td>\n",
       "      <td>1.03 (0.009)</td>\n",
       "      <td>1.00 (0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>1.00 (0.001)</td>\n",
       "      <td>1.02 (0.004)</td>\n",
       "      <td>1.01 (0.001)</td>\n",
       "      <td>1.02 (0.004)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "algorithm                                  BICO Group Sampling     Ray Maker  \\\n",
       "dataset   k   coreset_size_factor                                              \n",
       "Benchmark 10  50                      nan (nan)      nan (nan)     nan (nan)   \n",
       "              100                     nan (nan)      nan (nan)     nan (nan)   \n",
       "              200                     nan (nan)      nan (nan)     nan (nan)   \n",
       "              500                     nan (nan)      nan (nan)     nan (nan)   \n",
       "          20  50                      nan (nan)      nan (nan)     nan (nan)   \n",
       "...                                         ...            ...           ...   \n",
       "Tower     80  500                  1.00 (0.001)   1.02 (0.005)  1.01 (0.001)   \n",
       "          100 50                   1.04 (0.008)   1.03 (0.016)  1.26 (0.016)   \n",
       "              100                  1.02 (0.003)   1.02 (0.007)  1.07 (0.004)   \n",
       "              200                  1.01 (0.003)   1.02 (0.008)  1.02 (0.003)   \n",
       "              500                  1.00 (0.001)   1.02 (0.004)  1.01 (0.001)   \n",
       "\n",
       "algorithm                         Sensitivity Sampling    StreamKM++  \n",
       "dataset   k   coreset_size_factor                                     \n",
       "Benchmark 10  50                             nan (nan)     nan (nan)  \n",
       "              100                            nan (nan)     nan (nan)  \n",
       "              200                            nan (nan)     nan (nan)  \n",
       "              500                            nan (nan)           NaN  \n",
       "          20  50                             nan (nan)     nan (nan)  \n",
       "...                                                ...           ...  \n",
       "Tower     80  500                         1.02 (0.008)           NaN  \n",
       "          100 50                          1.08 (0.021)  1.01 (0.002)  \n",
       "              100                         1.05 (0.014)  1.01 (0.001)  \n",
       "              200                         1.03 (0.009)  1.00 (0.001)  \n",
       "              500                         1.02 (0.004)           NaN  \n",
       "\n",
       "[196 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_combined_mean_std(df=df_aggr_costs, attr=\"distortion_synthetic2\")\n",
    "\n",
    "df_results_table = pd.pivot_table(\n",
    "    data=df_aggr_costs,\n",
    "    values=\"distortion_synthetic2_mean_std\",\n",
    "    index=[\"dataset\", \"k\", \"coreset_size_factor\"],\n",
    "    columns=[\"algorithm\"],\n",
    "    aggfunc=lambda x: ' '.join(x)\n",
    ")\n",
    "df_results_table.to_excel(\"distortions-convex-clustering.xlsx\")\n",
    "df_results_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca06a71-87c6-472b-bd46-6ca36e450880",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9be732e4-b944-4ab5-9b6e-1b8a33e1436c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{longtable}{llrrrrr}\n",
      "\\multicolumn{7}{c}{\\textbf{Running times on the \\textit{Benchmark} data set}} \\\\\n",
      "\\toprule\n",
      "\\parbox[t]{5mm}{\\ \\\\$k$} & \\parbox[t]{5mm}{\\ \\\\$m$} &     BICO &  \\parbox[t]{1.5cm}{Group\\\\Sampling}  &   Ray Maker & \\parbox[t]{1.5cm}{Sensitivity\\\\Sampling} &    StreamKM++ \\\\\n",
      "\\midrule\n",
      "10 & 50  &    19 (3) &       117 (10) &    138 (15) &             106 (10) &      736 (60) \\\\\n",
      "   & 100 &    20 (4) &        120 (7) &    143 (17) &              107 (8) &     1460 (87) \\\\\n",
      "   & 200 &    25 (3) &       118 (10) &    151 (19) &              108 (8) &    2889 (139) \\\\\n",
      "   & 500 &    31 (7) &        125 (9) &    188 (10) &             105 (14) &  \\\\\n",
      " \\midrule\n",
      "20 & 50  &   104 (7) &      1016 (74) &    904 (68) &             933 (81) &    7233 (555) \\\\\n",
      "   & 100 &  124 (14) &      1021 (77) &    918 (72) &            913 (112) &   14546 (528) \\\\\n",
      "   & 200 &  176 (12) &      1004 (73) &    960 (77) &             933 (89) &  28532 (1115) \\\\\n",
      "   & 500 &  298 (52) &      1014 (54) &  1040 (128) &            930 (101) &  \\\\\n",
      " \\midrule\n",
      "30 & 50  &    36 (3) &       440 (36) &    356 (30) &             420 (29) &    3344 (306) \\\\\n",
      "   & 100 &    41 (3) &       440 (37) &    362 (30) &             418 (45) &    6433 (464) \\\\\n",
      "   & 200 &    49 (3) &       442 (30) &    371 (30) &             423 (37) &   12431 (969) \\\\\n",
      "   & 500 &    70 (2) &       445 (43) &    410 (28) &             424 (43) &  \\\\\n",
      " \\midrule\n",
      "40 & 50  &   124 (7) &     2064 (157) &  1480 (124) &           1917 (200) &   18387 (918) \\\\\n",
      "   & 100 &  154 (13) &     2032 (181) &  1513 (120) &           1931 (189) &  36296 (1090) \\\\\n",
      "   & 200 &  175 (15) &     2079 (160) &  1534 (120) &           1919 (202) &  64835 (2254) \\\\\n",
      "   & 500 &  240 (18) &      2068 (80) &  1596 (128) &            2005 (97) &            \\\\\n",
      "\\bottomrule\n",
      "\\caption{Running times (in seconds) of the evaluated algorithms on the \\textit{Benchmark} data set. Each cell specify the mean along with the standard deviation in parenthesis of 10 repetitions of the experiment.}\n",
      "\\label{tab:running-time-mean-benchmark}\n",
      "\\end{longtable}\n",
      "\n",
      "\\begin{longtable}{llrrrrr}\n",
      "\\multicolumn{7}{c}{\\textbf{Running times on the \\textit{Caltech} data set}} \\\\\n",
      "\\toprule\n",
      "\\parbox[t]{5mm}{\\ \\\\$k$} & \\parbox[t]{5mm}{\\ \\\\$m$} &     BICO &  \\parbox[t]{1.5cm}{Group\\\\Sampling}  &   Ray Maker & \\parbox[t]{1.5cm}{Sensitivity\\\\Sampling} &     StreamKM++ \\\\\n",
      "\\midrule\n",
      "10 & 50  &   133 (9) &      1039 (33) &  1146 (134) &             940 (98) &     5799 (309) \\\\\n",
      "   & 100 &  151 (12) &      1020 (55) &   1202 (49) &             949 (92) &    11026 (675) \\\\\n",
      "   & 200 &  180 (22) &      1029 (53) &  1218 (118) &             974 (34) &    21922 (952) \\\\\n",
      "   & 500 &  233 (17) &       933 (65) &   1302 (39) &             877 (61) &   \\\\\n",
      " \\midrule\n",
      "20 & 50  &  144 (16) &     1549 (113) &   1400 (85) &           1447 (106) &    11418 (441) \\\\\n",
      "   & 100 &  191 (18) &      1566 (72) &   1439 (37) &            1458 (90) &    22963 (649) \\\\\n",
      "   & 200 &  195 (13) &      1561 (65) &   1466 (82) &            1472 (92) &   44830 (1023) \\\\\n",
      "   & 500 &  373 (55) &      1428 (80) &   1475 (91) &            1349 (49) &   \\\\\n",
      " \\midrule\n",
      "30 & 50  &   170 (8) &     2060 (125) &  1633 (113) &           1943 (141) &    16920 (715) \\\\\n",
      "   & 100 &  171 (11) &      2071 (98) &   1664 (80) &           1946 (142) &   33911 (1532) \\\\\n",
      "   & 200 &  233 (36) &     2051 (152) &  1675 (120) &            1980 (81) &   66665 (2266) \\\\\n",
      "   & 500 &  393 (46) &      1861 (97) &   1701 (92) &            1814 (63) &   \\\\\n",
      " \\midrule\n",
      "40 & 50  &  177 (19) &     2566 (180) &  1846 (169) &           2442 (202) &   22409 (1109) \\\\\n",
      "   & 100 &  193 (18) &     2588 (168) &  1860 (154) &           2445 (124) &   43943 (1369) \\\\\n",
      "   & 200 &  266 (49) &     2605 (145) &  1898 (173) &            2478 (62) &   88300 (2367) \\\\\n",
      "   & 500 &  492 (63) &     2466 (111) &  1946 (127) &           2296 (109) &   \\\\\n",
      " \\midrule\n",
      "50 & 50  &  163 (12) &     3149 (126) &  2095 (156) &           2887 (197) &   27940 (1348) \\\\\n",
      "   & 100 &  206 (18) &     3084 (214) &  2137 (134) &           2916 (137) &   55743 (1457) \\\\\n",
      "   & 200 &  320 (36) &     3110 (155) &  2169 (158) &           2935 (138) &  111393 (2884) \\\\\n",
      "   & 500 &  556 (74) &      2930 (95) &   2098 (61) &           2664 (100) &             \\\\\n",
      "\\bottomrule\n",
      "\\caption{Running times (in seconds) of the evaluated algorithms on the \\textit{Caltech} data set. Each cell specify the mean along with the standard deviation in parenthesis of 10 repetitions of the experiment.}\n",
      "\\label{tab:running-time-mean-caltech}\n",
      "\\end{longtable}\n",
      "\n",
      "\\begin{longtable}{llrrrrr}\n",
      "\\multicolumn{7}{c}{\\textbf{Running times on the \\textit{Caltech} data set (with PCA preprocessing)}} \\\\\n",
      "\\toprule\n",
      "\\parbox[t]{5mm}{\\ \\\\$k$} & \\parbox[t]{5mm}{\\ \\\\$m$} &     BICO &  \\parbox[t]{1.5cm}{Group\\\\Sampling}  &   Ray Maker & \\parbox[t]{1.5cm}{Sensitivity\\\\Sampling} &    StreamKM++ \\\\\n",
      "\\midrule\n",
      "10 & 50  &  325 (16) &     1452 (112) &  1569 (174) &           1357 (153) &    6156 (268) \\\\\n",
      "   & 100 &  326 (25) &     1449 (118) &  1596 (135) &           1360 (114) &   11401 (454) \\\\\n",
      "   & 200 &  334 (27) &     1425 (161) &  1568 (222) &           1383 (113) &  21289 (1324) \\\\\n",
      "   & 500 &  386 (27) &      1386 (91) &   1685 (94) &            1357 (77) &  \\\\\n",
      " \\midrule\n",
      "20 & 50  &  362 (26) &     1934 (179) &  1753 (166) &           1783 (223) &   10751 (914) \\\\\n",
      "   & 100 &  379 (29) &     1895 (222) &  1796 (128) &           1833 (143) &  20680 (1273) \\\\\n",
      "   & 200 &  403 (39) &     1951 (143) &  1855 (143) &           1784 (216) &  40903 (3138) \\\\\n",
      "   & 500 &  489 (28) &     1833 (162) &  1898 (154) &            1800 (71) &  \\\\\n",
      " \\midrule\n",
      "30 & 50  &  346 (24) &     2401 (234) &  1999 (135) &           2257 (182) &   16026 (865) \\\\\n",
      "   & 100 &  373 (25) &     2443 (185) &  2011 (139) &           2276 (192) &   31501 (995) \\\\\n",
      "   & 200 &  422 (26) &     2430 (186) &  2019 (178) &           2277 (185) &  60330 (4284) \\\\\n",
      "   & 500 &  571 (35) &      2361 (97) &   2131 (89) &            2235 (61) &  \\\\\n",
      " \\midrule\n",
      "40 & 50  &  355 (22) &     2870 (270) &  2144 (184) &           2748 (202) &   21992 (620) \\\\\n",
      "   & 100 &  399 (33) &     2904 (211) &  2204 (157) &           2710 (255) &  41273 (1086) \\\\\n",
      "   & 200 &  432 (35) &     2892 (273) &  2213 (177) &           2744 (215) &  79148 (6325) \\\\\n",
      "   & 500 &  595 (55) &     2852 (103) &   2337 (78) &            2593 (94) &  \\\\\n",
      " \\midrule\n",
      "50 & 50  &  363 (23) &     3320 (323) &  2369 (200) &           3126 (316) &   26609 (600) \\\\\n",
      "   & 100 &  392 (33) &     3354 (293) &  2405 (195) &           3163 (287) &  51562 (2479) \\\\\n",
      "   & 200 &  432 (33) &     3405 (261) &  2445 (210) &           3156 (285) &  98934 (4995) \\\\\n",
      "   & 500 &  657 (47) &     3306 (122) &  2531 (111) &           3041 (162) &            \\\\\n",
      "\\bottomrule\n",
      "\\caption{Running times (in seconds) of the evaluated algorithms on the \\textit{Caltech} data set (with PCA preprocessing). Each cell specify the mean along with the standard deviation in parenthesis of 10 repetitions of the experiment.}\n",
      "\\label{tab:running-time-mean-caltech-pca}\n",
      "\\end{longtable}\n",
      "\n",
      "\\begin{longtable}{llrrrrr}\n",
      "\\multicolumn{7}{c}{\\textbf{Running times on the \\textit{Census} data set}} \\\\\n",
      "\\toprule\n",
      "\\parbox[t]{5mm}{\\ \\\\$k$} & \\parbox[t]{5mm}{\\ \\\\$m$} &     BICO &  \\parbox[t]{1.5cm}{Group\\\\Sampling}  & Ray Maker & \\parbox[t]{1.5cm}{Sensitivity\\\\Sampling} &    StreamKM++ \\\\\n",
      "\\midrule\n",
      "10 & 50  &    47 (6) &       265 (33) &  300 (34) &             239 (37) &    1866 (176) \\\\\n",
      "   & 100 &    57 (2) &       318 (27) &  400 (15) &             291 (23) &    4080 (273) \\\\\n",
      "   & 200 &    61 (4) &       329 (18) &  438 (26) &             286 (29) &    8203 (231) \\\\\n",
      "   & 500 &    69 (4) &       314 (35) &  534 (36) &             281 (42) &  \\\\\n",
      " \\midrule\n",
      "20 & 50  &    48 (5) &       444 (61) &  373 (49) &             401 (54) &    3584 (239) \\\\\n",
      "   & 100 &    55 (5) &       512 (40) &  474 (28) &             469 (12) &    8107 (529) \\\\\n",
      "   & 200 &    62 (4) &       498 (27) &  505 (25) &             450 (15) &   15862 (582) \\\\\n",
      "   & 500 &    83 (4) &       538 (26) &  624 (55) &             450 (37) &  \\\\\n",
      " \\midrule\n",
      "30 & 50  &    47 (3) &       599 (73) &  448 (75) &             523 (79) &    4877 (259) \\\\\n",
      "   & 100 &    60 (4) &       698 (28) &  522 (27) &             607 (28) &   12061 (765) \\\\\n",
      "   & 200 &    66 (7) &       700 (23) &  593 (24) &             611 (35) &  23266 (1072) \\\\\n",
      "   & 500 &    99 (8) &       660 (67) &  684 (42) &             638 (38) &  \\\\\n",
      " \\midrule\n",
      "40 & 50  &    50 (5) &      772 (103) &  503 (40) &             662 (85) &    6507 (372) \\\\\n",
      "   & 100 &    62 (4) &       881 (20) &  616 (35) &             783 (47) &   15837 (759) \\\\\n",
      "   & 200 &    73 (4) &       863 (32) &  655 (29) &             784 (59) &  31133 (1827) \\\\\n",
      "   & 500 &  135 (13) &       858 (87) &  779 (45) &             802 (51) &  \\\\\n",
      " \\midrule\n",
      "50 & 50  &    51 (7) &       934 (84) &  574 (87) &             803 (98) &    7680 (467) \\\\\n",
      "   & 100 &    66 (3) &      1051 (32) &  694 (24) &             936 (76) &   19651 (747) \\\\\n",
      "   & 200 &    81 (3) &      1054 (37) &  730 (29) &             922 (74) &  38624 (1771) \\\\\n",
      "   & 500 &  172 (20) &      1062 (86) &  845 (39) &             977 (50) &            \\\\\n",
      "\\bottomrule\n",
      "\\caption{Running times (in seconds) of the evaluated algorithms on the \\textit{Census} data set. Each cell specify the mean along with the standard deviation in parenthesis of 10 repetitions of the experiment.}\n",
      "\\label{tab:running-time-mean-census}\n",
      "\\end{longtable}\n",
      "\n",
      "\\begin{longtable}{llrrrrr}\n",
      "\\multicolumn{7}{c}{\\textbf{Running times on the \\textit{Census} data set (with PCA preprocessing)}} \\\\\n",
      "\\toprule\n",
      "\\parbox[t]{5mm}{\\ \\\\$k$} & \\parbox[t]{5mm}{\\ \\\\$m$} &     BICO &  \\parbox[t]{1.5cm}{Group\\\\Sampling}  &  Ray Maker & \\parbox[t]{1.5cm}{Sensitivity\\\\Sampling} &    StreamKM++ \\\\\n",
      "\\midrule\n",
      "10 & 50  &   103 (8) &       529 (38) &   535 (87) &             479 (40) &    2089 (224) \\\\\n",
      "   & 100 &   105 (8) &       505 (61) &   593 (49) &             481 (37) &    4153 (376) \\\\\n",
      "   & 200 &   106 (6) &       517 (40) &   630 (62) &             477 (45) &    7587 (443) \\\\\n",
      "   & 500 &  114 (10) &       483 (38) &   706 (54) &             463 (28) &  \\\\\n",
      " \\midrule\n",
      "20 & 50  &   107 (7) &       702 (62) &   646 (48) &             635 (74) &    4037 (384) \\\\\n",
      "   & 100 &   110 (7) &       694 (71) &   667 (46) &             642 (58) &    8010 (410) \\\\\n",
      "   & 200 &   113 (7) &       701 (57) &   694 (58) &             647 (57) &   14984 (979) \\\\\n",
      "   & 500 &   140 (8) &       690 (30) &   775 (42) &             626 (29) &  \\\\\n",
      " \\midrule\n",
      "30 & 50  &   112 (8) &       870 (94) &   701 (71) &             813 (62) &    5947 (492) \\\\\n",
      "   & 100 &   115 (7) &       879 (95) &   731 (64) &             815 (61) &   11560 (493) \\\\\n",
      "   & 200 &   122 (8) &       880 (96) &   761 (69) &             820 (62) &   22705 (935) \\\\\n",
      "   & 500 &   164 (6) &       891 (23) &   854 (45) &             800 (24) &  \\\\\n",
      " \\midrule\n",
      "40 & 50  &   113 (6) &      1073 (92) &  769 (100) &             982 (72) &    8021 (395) \\\\\n",
      "   & 100 &  120 (10) &     1068 (108) &   816 (54) &             982 (74) &   15201 (854) \\\\\n",
      "   & 200 &  127 (12) &      1075 (91) &   824 (87) &             995 (75) &  29927 (2012) \\\\\n",
      "   & 500 &  199 (11) &      1063 (47) &   904 (57) &             938 (37) &  \\\\\n",
      " \\midrule\n",
      "50 & 50  &  114 (11) &      1257 (96) &   861 (66) &            1155 (83) &    9655 (578) \\\\\n",
      "   & 100 &   121 (9) &     1244 (155) &   887 (70) &            1144 (91) &  19140 (1164) \\\\\n",
      "   & 200 &  134 (11) &      1266 (92) &   922 (68) &            1152 (87) &  36861 (2182) \\\\\n",
      "   & 500 &  243 (14) &      1225 (54) &  1007 (32) &            1113 (55) &            \\\\\n",
      "\\bottomrule\n",
      "\\caption{Running times (in seconds) of the evaluated algorithms on the \\textit{Census} data set (with PCA preprocessing). Each cell specify the mean along with the standard deviation in parenthesis of 10 repetitions of the experiment.}\n",
      "\\label{tab:running-time-mean-census-pca}\n",
      "\\end{longtable}\n",
      "\n",
      "\\begin{longtable}{llrrrrr}\n",
      "\\multicolumn{7}{c}{\\textbf{Running times on the \\textit{Covertype} data set}} \\\\\n",
      "\\toprule\n",
      "\\parbox[t]{5mm}{\\ \\\\$k$} & \\parbox[t]{5mm}{\\ \\\\$m$} &   BICO &  \\parbox[t]{1.5cm}{Group\\\\Sampling}  & Ray Maker & \\parbox[t]{1.5cm}{Sensitivity\\\\Sampling} &  StreamKM++ \\\\\n",
      "\\midrule\n",
      "10 & 50  &   8 (1) &         58 (9) &    60 (8) &               50 (8) &    275 (37) \\\\\n",
      "   & 100 &   8 (1) &         61 (7) &    67 (9) &               48 (9) &    597 (69) \\\\\n",
      "   & 200 &   9 (1) &         57 (7) &    85 (9) &               51 (9) &  1322 (214) \\\\\n",
      "   & 500 &  12 (1) &         67 (7) &  123 (18) &               55 (5) &\\\\\n",
      " \\midrule\n",
      "20 & 50  &   9 (1) &        93 (13) &   70 (10) &              77 (12) &    580 (80) \\\\\n",
      "   & 100 &   9 (1) &         88 (8) &   81 (11) &              74 (12) &  1038 (183) \\\\\n",
      "   & 200 &  10 (1) &         93 (9) &   90 (11) &              79 (13) &  2603 (385) \\\\\n",
      "   & 500 &  19 (1) &        108 (7) &   131 (9) &               84 (9) &\\\\\n",
      " \\midrule\n",
      "30 & 50  &   8 (1) &       125 (15) &   84 (11) &             104 (18) &   888 (148) \\\\\n",
      "   & 100 &  10 (1) &       125 (13) &   87 (11) &             105 (19) &  1593 (211) \\\\\n",
      "   & 200 &  12 (2) &       125 (14) &   99 (14) &             105 (20) &  3755 (463) \\\\\n",
      "   & 500 &  25 (2) &       146 (10) &  139 (14) &              122 (8) &\\\\\n",
      " \\midrule\n",
      "40 & 50  &   8 (1) &       156 (19) &   97 (10) &             132 (23) &   1146 (89) \\\\\n",
      "   & 100 &  10 (1) &       158 (19) &  101 (19) &             132 (21) &  2251 (239) \\\\\n",
      "   & 200 &  14 (2) &       159 (20) &  120 (15) &             132 (21) &  5308 (681) \\\\\n",
      "   & 500 &  38 (4) &       189 (10) &  157 (15) &             147 (12) &\\\\\n",
      " \\midrule\n",
      "50 & 50  &   9 (1) &       191 (24) &  109 (20) &             153 (27) &  1467 (184) \\\\\n",
      "   & 100 &  11 (1) &       187 (20) &  114 (22) &             157 (27) &  2491 (318) \\\\\n",
      "   & 200 &  16 (3) &       186 (16) &  128 (20) &             163 (30) &  6057 (672) \\\\\n",
      "   & 500 &  48 (5) &       231 (10) &   181 (9) &             185 (12) &          \\\\\n",
      "\\bottomrule\n",
      "\\caption{Running times (in seconds) of the evaluated algorithms on the \\textit{Covertype} data set. Each cell specify the mean along with the standard deviation in parenthesis of 10 repetitions of the experiment.}\n",
      "\\label{tab:running-time-mean-covertype}\n",
      "\\end{longtable}\n",
      "\n",
      "\\begin{longtable}{llrrrrr}\n",
      "\\multicolumn{7}{c}{\\textbf{Running times on the \\textit{Covertype} data set (with PCA preprocessing)}} \\\\\n",
      "\\toprule\n",
      "\\parbox[t]{5mm}{\\ \\\\$k$} & \\parbox[t]{5mm}{\\ \\\\$m$} &   BICO &  \\parbox[t]{1.5cm}{Group\\\\Sampling}  & Ray Maker & \\parbox[t]{1.5cm}{Sensitivity\\\\Sampling} &  StreamKM++ \\\\\n",
      "\\midrule\n",
      "10 & 50  &  19 (2) &        100 (8) &  101 (10) &               86 (8) &    417 (45) \\\\\n",
      "   & 100 &  18 (1) &         99 (7) &   111 (9) &              84 (10) &    797 (58) \\\\\n",
      "   & 200 &  19 (1) &         98 (7) &  118 (14) &               87 (8) &   1579 (63) \\\\\n",
      "   & 500 &  22 (1) &        90 (10) &  148 (14) &               84 (7) &\\\\\n",
      " \\midrule\n",
      "20 & 50  &  19 (1) &       141 (10) &  116 (10) &              119 (9) &    781 (91) \\\\\n",
      "   & 100 &  19 (2) &       137 (13) &   122 (8) &             116 (11) &  1452 (186) \\\\\n",
      "   & 200 &  21 (2) &       136 (13) &   134 (7) &             115 (11) &  2958 (238) \\\\\n",
      "   & 500 &  29 (1) &       136 (12) &  160 (12) &              113 (8) &\\\\\n",
      " \\midrule\n",
      "30 & 50  &  19 (1) &       175 (18) &  132 (12) &             149 (15) &   1170 (97) \\\\\n",
      "   & 100 &  20 (2) &       175 (20) &  138 (13) &             154 (11) &  2198 (312) \\\\\n",
      "   & 200 &  23 (2) &       180 (15) &  146 (17) &             150 (13) &  4430 (307) \\\\\n",
      "   & 500 &  37 (3) &        174 (7) &  170 (14) &             145 (14) &\\\\\n",
      " \\midrule\n",
      "40 & 50  &  19 (1) &       214 (20) &  147 (12) &             181 (17) &  1455 (192) \\\\\n",
      "   & 100 &  22 (2) &       220 (18) &  149 (12) &             185 (12) &  2890 (301) \\\\\n",
      "   & 200 &  25 (2) &       222 (18) &  165 (13) &             185 (13) &  5686 (644) \\\\\n",
      "   & 500 &  47 (4) &       212 (11) &  196 (13) &             179 (16) &\\\\\n",
      " \\midrule\n",
      "50 & 50  &  20 (1) &       254 (29) &  160 (12) &             214 (18) &  1866 (180) \\\\\n",
      "   & 100 &  22 (2) &       264 (20) &  168 (13) &             211 (16) &  3840 (157) \\\\\n",
      "   & 200 &  29 (2) &       260 (20) &  177 (16) &             214 (17) &  7186 (493) \\\\\n",
      "   & 500 &  60 (4) &       254 (13) &  203 (13) &             203 (24) &          \\\\\n",
      "\\bottomrule\n",
      "\\caption{Running times (in seconds) of the evaluated algorithms on the \\textit{Covertype} data set (with PCA preprocessing). Each cell specify the mean along with the standard deviation in parenthesis of 10 repetitions of the experiment.}\n",
      "\\label{tab:running-time-mean-covertype-pca}\n",
      "\\end{longtable}\n",
      "\n",
      "\\begin{longtable}{llrrrrr}\n",
      "\\multicolumn{7}{c}{\\textbf{Running times on the \\textit{NYTimes} data set}} \\\\\n",
      "\\toprule\n",
      "\\parbox[t]{5mm}{\\ \\\\$k$} & \\parbox[t]{5mm}{\\ \\\\$m$} &       BICO &  \\parbox[t]{1.5cm}{Group\\\\Sampling}  & Ray Maker & \\parbox[t]{1.5cm}{Sensitivity\\\\Sampling} &  StreamKM++ \\\\\n",
      "\\midrule\n",
      "10 & 50  &      12 (2) &         58 (6) &    68 (3) &               56 (1) &    369 (19) \\\\\n",
      "   & 100 &      16 (5) &         54 (2) &    65 (4) &               49 (3) &    708 (42) \\\\\n",
      "   & 200 &      33 (7) &         51 (2) &    64 (2) &               49 (3) &  1373 (173) \\\\\n",
      "   & 500 &    107 (24) &         52 (6) &    76 (8) &               52 (4) &\\\\\n",
      " \\midrule\n",
      "20 & 50  &      20 (5) &         92 (5) &    84 (2) &               88 (3) &    670 (70) \\\\\n",
      "   & 100 &     36 (12) &         85 (6) &    75 (5) &               79 (6) &  1338 (112) \\\\\n",
      "   & 200 &    101 (29) &         79 (5) &    76 (4) &               78 (4) &  2681 (228) \\\\\n",
      "   & 500 &   374 (139) &         83 (9) &   86 (10) &               80 (8) &\\\\\n",
      " \\midrule\n",
      "30 & 50  &      25 (6) &        124 (4) &    97 (3) &              117 (4) &   1023 (89) \\\\\n",
      "   & 100 &     61 (21) &       111 (10) &    88 (4) &             109 (13) &  2032 (176) \\\\\n",
      "   & 200 &    178 (53) &        108 (5) &    90 (3) &             108 (14) &  3775 (342) \\\\\n",
      "   & 500 &   715 (456) &        110 (9) &   106 (8) &             112 (11) &\\\\\n",
      " \\midrule\n",
      "40 & 50  &     29 (15) &        156 (4) &   112 (4) &              149 (4) &   1432 (46) \\\\\n",
      "   & 100 &     86 (26) &       138 (10) &   100 (6) &             139 (17) &  2771 (168) \\\\\n",
      "   & 200 &    294 (65) &       135 (17) &   103 (2) &             137 (16) &  5548 (351) \\\\\n",
      "   & 500 &  1110 (401) &       140 (18) &  119 (10) &             138 (12) &\\\\\n",
      " \\midrule\n",
      "50 & 50  &     46 (15) &       180 (25) &   125 (4) &              181 (7) &  1689 (190) \\\\\n",
      "   & 100 &    114 (37) &       162 (20) &   115 (7) &             165 (15) &   3537 (48) \\\\\n",
      "   & 200 &   375 (136) &        168 (3) &   117 (7) &             163 (15) &  6464 (573) \\\\\n",
      "   & 500 &   886 (547) &       174 (11) &  131 (12) &             166 (17) &          \\\\\n",
      "\\bottomrule\n",
      "\\caption{Running times (in seconds) of the evaluated algorithms on the \\textit{NYTimes} data set. Each cell specify the mean along with the standard deviation in parenthesis of 10 repetitions of the experiment.}\n",
      "\\label{tab:running-time-mean-nytimes}\n",
      "\\end{longtable}\n",
      "\n",
      "\\begin{longtable}{llrrrrr}\n",
      "\\multicolumn{7}{c}{\\textbf{Running times on the \\textit{NYTimes} data set (with PCA preprocessing)}} \\\\\n",
      "\\toprule\n",
      "\\parbox[t]{5mm}{\\ \\\\$k$} & \\parbox[t]{5mm}{\\ \\\\$m$} &     BICO &  \\parbox[t]{1.5cm}{Group\\\\Sampling}  & Ray Maker & \\parbox[t]{1.5cm}{Sensitivity\\\\Sampling} &  StreamKM++ \\\\\n",
      "\\midrule\n",
      "10 & 50  &    18 (0) &         28 (1) &    28 (0) &               26 (0) &      71 (3) \\\\\n",
      "   & 100 &    18 (0) &         28 (2) &    30 (1) &               25 (1) &    109 (17) \\\\\n",
      "   & 200 &    19 (0) &         28 (1) &    33 (1) &               26 (0) &    199 (19) \\\\\n",
      "   & 500 &    20 (0) &         29 (0) &    47 (4) &               26 (1) &\\\\\n",
      " \\midrule\n",
      "20 & 50  &    30 (0) &         51 (4) &    50 (1) &               49 (2) &     203 (3) \\\\\n",
      "   & 100 &    31 (0) &         54 (2) &    50 (3) &               50 (2) &     375 (6) \\\\\n",
      "   & 200 &    32 (0) &         55 (1) &    55 (1) &               50 (3) &    610 (74) \\\\\n",
      "   & 500 &    40 (1) &         54 (2) &    69 (2) &               51 (2) &\\\\\n",
      " \\midrule\n",
      "30 & 50  &    40 (0) &         79 (7) &    72 (4) &               77 (3) &    403 (14) \\\\\n",
      "   & 100 &    42 (0) &         83 (2) &    75 (3) &               78 (3) &   690 (107) \\\\\n",
      "   & 200 &    45 (1) &        80 (10) &    78 (3) &               77 (4) &  1258 (141) \\\\\n",
      "   & 500 &    68 (3) &         87 (3) &    92 (7) &               81 (3) &\\\\\n",
      " \\midrule\n",
      "40 & 50  &    49 (1) &       109 (11) &    94 (5) &              105 (6) &    624 (77) \\\\\n",
      "   & 100 &    52 (1) &       110 (12) &    93 (5) &              110 (3) &   1225 (75) \\\\\n",
      "   & 200 &    60 (1) &       109 (17) &    99 (4) &              104 (8) &  2055 (148) \\\\\n",
      "   & 500 &   114 (6) &       118 (10) &   118 (6) &              116 (3) &\\\\\n",
      " \\midrule\n",
      "50 & 50  &    61 (1) &       136 (23) &   123 (5) &             143 (10) &    995 (21) \\\\\n",
      "   & 100 &    66 (1) &       147 (20) &   121 (6) &              152 (9) &  1846 (151) \\\\\n",
      "   & 200 &    78 (3) &       133 (18) &   125 (5) &             145 (10) &  2980 (262) \\\\\n",
      "   & 500 &  183 (11) &       156 (19) &   150 (6) &              153 (7) &          \\\\\n",
      "\\bottomrule\n",
      "\\caption{Running times (in seconds) of the evaluated algorithms on the \\textit{NYTimes} data set (with PCA preprocessing). Each cell specify the mean along with the standard deviation in parenthesis of 10 repetitions of the experiment.}\n",
      "\\label{tab:running-time-mean-nytimes-pca}\n",
      "\\end{longtable}\n",
      "\n",
      "\\begin{longtable}{llrrrrr}\n",
      "\\multicolumn{7}{c}{\\textbf{Running times on the \\textit{Tower} data set}} \\\\\n",
      "\\toprule\n",
      " \\parbox[t]{5mm}{\\ \\\\$k$} & \\parbox[t]{5mm}{\\ \\\\$m$} &   BICO &  \\parbox[t]{1.5cm}{Group\\\\Sampling}  & Ray Maker & \\parbox[t]{1.5cm}{Sensitivity\\\\Sampling} &   StreamKM++ \\\\\n",
      "\\midrule\n",
      "20  & 50  &   8 (2) &       266 (12) &    66 (3) &               68 (2) &     685 (11) \\\\\n",
      "    & 100 &   8 (2) &       268 (13) &    91 (5) &               71 (4) &    1373 (14) \\\\\n",
      "    & 200 &   7 (1) &       268 (12) &  135 (12) &               71 (4) &    2746 (14) \\\\\n",
      "    & 500 &   8 (2) &        265 (8) &  268 (11) &               70 (2) & \\\\\n",
      " \\midrule\n",
      "40  & 50  &   8 (2) &       546 (10) &    92 (2) &              133 (5) &    1368 (21) \\\\\n",
      "    & 100 &   7 (1) &       552 (14) &   112 (2) &              134 (4) &    2747 (21) \\\\\n",
      "    & 200 &   8 (1) &       548 (14) &   155 (3) &              136 (5) &    5478 (35) \\\\\n",
      "    & 500 &  10 (2) &       547 (16) &   269 (7) &              136 (2) & \\\\\n",
      " \\midrule\n",
      "60  & 50  &   6 (1) &       831 (19) &   120 (3) &              195 (8) &    2050 (38) \\\\\n",
      "    & 100 &   7 (1) &       832 (14) &   139 (2) &              199 (6) &    4121 (88) \\\\\n",
      "    & 200 &   7 (1) &       842 (13) &   183 (2) &              201 (5) &   8162 (253) \\\\\n",
      "    & 500 &  14 (4) &       835 (17) &   306 (8) &              202 (5) & \\\\\n",
      " \\midrule\n",
      "80  & 50  &   7 (2) &      1125 (20) &   148 (3) &              261 (6) &    2730 (89) \\\\\n",
      "    & 100 &   8 (2) &      1125 (12) &   167 (4) &              263 (6) &   5354 (281) \\\\\n",
      "    & 200 &   9 (2) &      1129 (21) &   211 (6) &              267 (5) &  10819 (514) \\\\\n",
      "    & 500 &  20 (4) &      1122 (14) &  340 (11) &              269 (5) & \\\\\n",
      " \\midrule\n",
      "100 & 50  &   7 (2) &      1419 (22) &   175 (6) &              324 (8) &    3403 (36) \\\\\n",
      "    & 100 &   8 (1) &      1434 (21) &   198 (3) &              327 (7) &   6859 (120) \\\\\n",
      "    & 200 &  10 (1) &      1428 (15) &   241 (7) &              330 (7) &  13530 (475) \\\\\n",
      "    & 500 &  28 (7) &       1444 (9) &  384 (10) &              338 (5) &           \\\\\n",
      "\\bottomrule\n",
      "\\caption{Running times (in seconds) of the evaluated algorithms on the \\textit{Tower} data set. Each cell specify the mean along with the standard deviation in parenthesis of 10 repetitions of the experiment.}\n",
      "\\label{tab:running-time-mean-tower}\n",
      "\\end{longtable}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_aggr_costs[\"running_time_mean\"] = df_aggr_costs[\"running_time_mean\"].round(0).astype(int)\n",
    "\n",
    "def runtime_combiner(row) -> str:\n",
    "    attr = \"running_time\"\n",
    "    mean = row[f\"{attr}_mean\"]\n",
    "    std =  row[f\"{attr}_std\"]\n",
    "    return f\"{mean:0.0f} ({std:0.0f})\"\n",
    "df_aggr_costs[\"running_time_mean_std\"] = df_aggr_costs.apply(lambda x: runtime_combiner(x), axis=1)\n",
    "\n",
    "df_results_table = pd.pivot_table(\n",
    "    data=df_aggr_costs,\n",
    "    values=\"running_time_mean_std\",\n",
    "    index=[\"dataset\", \"k\", \"coreset_size_factor\"],\n",
    "    columns=[\"algorithm\"],\n",
    "    aggfunc=max\n",
    ")\n",
    "df_results_table = df_results_table.round(0)\n",
    "\n",
    "\n",
    "data_sets = sorted(list(set([keys[0] for keys in df_results_table.index])))\n",
    "    \n",
    "for data_set in data_sets:\n",
    "    data_set_without_pca = data_set.replace(\"+PCA\", \"\")\n",
    "    pca_tag = \" (with PCA preprocessing)\" if \"PCA\" in data_set else \"\"\n",
    "    data_set_text = f\"\\\\textit{{{data_set_without_pca}}} data set{pca_tag}\"\n",
    "    \n",
    "    top_text = r\"\\multicolumn{7}{c}{\\textbf{Running times on the \" + data_set_text + r\"}} \\\\\"\n",
    "    \n",
    "    output = df_results_table.loc[data_set].to_latex()\n",
    "    output = output.replace(r\"\\begin{tabular}{lllllll}\", r\"\\begin{longtable}{llrrrrr}\" + \"\\n\" +top_text)\n",
    "    output = output.replace(r\"& algorithm &\", r\"&  &\")\n",
    "    output = re.sub(r\"^k & [^&]+[^\\\\]+\\\\\\\\\", r\"\", output, flags=re.MULTILINE)\n",
    "    \n",
    "    output = output.replace(r\"   &  & \", r\"k & m &\")\n",
    "    output = output.replace(r\"k &\", r\"\\parbox[t]{5mm}{\\ \\\\$k$} &\")\n",
    "    output = output.replace(r\"m &\", r\"\\parbox[t]{5mm}{\\ \\\\$m$} &\")\n",
    "    \n",
    "    output = output.replace(r\"Group Sampling\", r\" \\parbox[t]{1.5cm}{Group\\\\Sampling} \")\n",
    "    output = output.replace(r\"     Ray Maker \", r\" \\parbox[t]{1.5cm}{Ray\\\\Maker} \")\n",
    "    output = output.replace(r\" Sensitivity Sampling \", r\" \\parbox[t]{1.5cm}{Sensitivity\\\\Sampling} \")\n",
    "    \n",
    "    output = output.replace(r\"NaN\", r\"\")\n",
    "    data_set_slug = data_set.replace(\"+\", \"-\").lower()\n",
    "    label_text = f\"\\\\label{{tab:running-time-mean-{data_set_slug}}}\"\n",
    "    \n",
    "    caption_text = f\"\\caption{{Running times (in seconds) of the evaluated algorithms on the {data_set_text}. Each cell specify the mean along with the standard deviation in parenthesis of 10 repetitions of the experiment.}}\"\n",
    "    output = output.replace(r\"\\end{tabular}\", f\"{caption_text}\\n{label_text}\\n\\\\end{{longtable}}\")\n",
    "    \n",
    "    for n in [10, 20, 30, 40, 50, 60, 80, 100]:\n",
    "        output = output.replace(f\"          \\\\\\\\\\n{n} \", f\"\\\\\\\\\\n \\\\midrule\\n{n} \")\n",
    "    \n",
    "    # Remove empty lines\n",
    "    output = output.replace(\"\\n\\n\", \"\\n\")\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495a19d2-6ac0-4713-8a6b-44481ae21dae",
   "metadata": {},
   "source": [
    "## Cost Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e5f6b51-785f-492c-b9d9-d9d8fba7f436",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_aggr_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11937646-af67-42dd-aa1c-91db93364b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>real_cost_min</th>\n",
       "      <th>real_cost_max</th>\n",
       "      <th>real_cost_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>k</th>\n",
       "      <th>algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Benchmark</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">10</th>\n",
       "      <th>BICO</th>\n",
       "      <td>4.580000e+06</td>\n",
       "      <td>4.760000e+06</td>\n",
       "      <td>1.039301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group Sampling</th>\n",
       "      <td>5.220000e+06</td>\n",
       "      <td>5.400000e+06</td>\n",
       "      <td>1.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ray Maker</th>\n",
       "      <td>4.940000e+06</td>\n",
       "      <td>5.060000e+06</td>\n",
       "      <td>1.024291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity Sampling</th>\n",
       "      <td>4.540000e+06</td>\n",
       "      <td>4.720000e+06</td>\n",
       "      <td>1.039648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StreamKM++</th>\n",
       "      <td>5.300000e+06</td>\n",
       "      <td>5.300000e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Tower</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">100</th>\n",
       "      <th>BICO</th>\n",
       "      <td>1.625935e+08</td>\n",
       "      <td>1.700597e+08</td>\n",
       "      <td>1.045920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group Sampling</th>\n",
       "      <td>1.650037e+08</td>\n",
       "      <td>1.720751e+08</td>\n",
       "      <td>1.042856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ray Maker</th>\n",
       "      <td>1.630296e+08</td>\n",
       "      <td>1.702870e+08</td>\n",
       "      <td>1.044516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity Sampling</th>\n",
       "      <td>1.657411e+08</td>\n",
       "      <td>1.737201e+08</td>\n",
       "      <td>1.048141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StreamKM++</th>\n",
       "      <td>1.640737e+08</td>\n",
       "      <td>1.680256e+08</td>\n",
       "      <td>1.024086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>245 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    real_cost_min  real_cost_max  \\\n",
       "dataset   k   algorithm                                            \n",
       "Benchmark 10  BICO                   4.580000e+06   4.760000e+06   \n",
       "              Group Sampling         5.220000e+06   5.400000e+06   \n",
       "              Ray Maker              4.940000e+06   5.060000e+06   \n",
       "              Sensitivity Sampling   4.540000e+06   4.720000e+06   \n",
       "              StreamKM++             5.300000e+06   5.300000e+06   \n",
       "...                                           ...            ...   \n",
       "Tower     100 BICO                   1.625935e+08   1.700597e+08   \n",
       "              Group Sampling         1.650037e+08   1.720751e+08   \n",
       "              Ray Maker              1.630296e+08   1.702870e+08   \n",
       "              Sensitivity Sampling   1.657411e+08   1.737201e+08   \n",
       "              StreamKM++             1.640737e+08   1.680256e+08   \n",
       "\n",
       "                                    real_cost_ratio  \n",
       "dataset   k   algorithm                              \n",
       "Benchmark 10  BICO                         1.039301  \n",
       "              Group Sampling               1.034483  \n",
       "              Ray Maker                    1.024291  \n",
       "              Sensitivity Sampling         1.039648  \n",
       "              StreamKM++                   1.000000  \n",
       "...                                             ...  \n",
       "Tower     100 BICO                         1.045920  \n",
       "              Group Sampling               1.042856  \n",
       "              Ray Maker                    1.044516  \n",
       "              Sensitivity Sampling         1.048141  \n",
       "              StreamKM++                   1.024086  \n",
       "\n",
       "[245 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_min_max = df_filtered.groupby([\"dataset\", \"k\", \"algorithm\"]).agg(\n",
    "    real_cost_min=(\"real_cost_mean\", \"min\"),\n",
    "    real_cost_max=(\"real_cost_mean\", \"max\"),\n",
    ")\n",
    "df_min_max[\"real_cost_ratio\"] = df_min_max.real_cost_max / df_min_max.real_cost_min\n",
    "df_min_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13b692f-800b-4fbf-84fd-99c751efa208",
   "metadata": {},
   "source": [
    "## Real Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f01a6d1-b27d-461c-a90e-24d833c51503",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'real_cost_mean_std'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6294/4167834190.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df_results_table = pd.pivot_table(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_aggr_costs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"real_cost_mean_std\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"k\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coreset_size_factor\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"algorithm\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/xrun-eubxByDy-py3.8/lib/python3.8/site-packages/pandas/core/reshape/pivot.py\u001b[0m in \u001b[0;36mpivot_table\u001b[0;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pivot_table\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     table = __internal_pivot_table(\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/xrun-eubxByDy-py3.8/lib/python3.8/site-packages/pandas/core/reshape/pivot.py\u001b[0m in \u001b[0;36m__internal_pivot_table\u001b[0;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mto_filter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'real_cost_mean_std'"
     ]
    }
   ],
   "source": [
    "df_results_table = pd.pivot_table(\n",
    "    data=df_aggr_costs,\n",
    "    values=\"real_cost_mean_std\",\n",
    "    index=[\"dataset\", \"k\", \"coreset_size_factor\"],\n",
    "    columns=[\"algorithm\"],\n",
    "    aggfunc=lambda x: ' '.join(x)\n",
    ")\n",
    "df_results_table.to_excel(\"real_costs.xlsx\")\n",
    "df_results_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60462eef-c26a-4035-bf50-60f3febb10a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generating Costs Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57381f83-4783-4e13-baf0-5caa88e05575",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "add_combined_mean_std(df=df_aggr_costs, attr=\"real_cost\", g_format=True)\n",
    "\n",
    "df_results_table = pd.pivot_table(\n",
    "    data=df_aggr_costs,\n",
    "    values=\"real_cost_mean_std\",\n",
    "    index=[\"dataset\", \"k\", \"coreset_size_factor\"],\n",
    "    columns=[\"algorithm\"],\n",
    "    aggfunc=lambda x: ' '.join(x)\n",
    ")\n",
    "\n",
    "\n",
    "data_sets = sorted(list(set([keys[0] for keys in df_results_table.index])))\n",
    "    \n",
    "for data_set in data_sets:\n",
    "    data_set_without_pca = data_set.replace(\"+PCA\", \"\")\n",
    "    pca_tag = \" (with PCA preprocessing)\" if \"PCA\" in data_set else \"\"\n",
    "    data_set_text = f\"\\\\textit{{{data_set_without_pca}}} data set{pca_tag}\"\n",
    "    \n",
    "    top_text = r\"\\multicolumn{7}{c}{\\textbf{Costs on the \" + data_set_text + r\"}} \\\\\"\n",
    "    \n",
    "    output = df_results_table.loc[data_set].to_latex()\n",
    "    output = output.replace(r\"\\begin{tabular}{lllllll}\", r\"\\begin{longtable}{lllllll}\" + \"\\n\" +top_text)\n",
    "    output = output.replace(r\"& algorithm &\", r\"&  &\")\n",
    "    output = output.replace(r\"k & coreset\\_size\\_factor &               &                &               &                      &               \\\\\", \"\")\n",
    "    output = output.replace(r\"k & coreset\\_size\\_factor &                &                &                &                      &               \\\\\", \"\")\n",
    "    output = output.replace(r\"k & coreset\\_size\\_factor &                    &                    &                    &                      &                    \\\\\", \"\")\n",
    "    output = output.replace(r\"   &  &          \", r\"k & m &\")\n",
    "    output = output.replace(r\"k &\", r\"\\parbox[t]{5mm}{\\ \\\\$k$} &\")\n",
    "    output = output.replace(r\"m &\", r\"\\parbox[t]{5mm}{\\ \\\\$m$} &\")\n",
    "    \n",
    "    output = output.replace(r\"Group Sampling\", r\"\\parbox[t]{1cm}{Group\\\\Sampling}\")\n",
    "    output = output.replace(r\"     Ray Maker \", r\"\\parbox[t]{1cm}{Ray\\\\Maker}\")\n",
    "    output = output.replace(r\" Sensitivity Sampling \", r\"\\parbox[t]{1cm}{Sensitivity\\\\Sampling}\")\n",
    "    \n",
    "    output = output.replace(r\"NaN\", r\"\")\n",
    "    data_set_slug = data_set.replace(\"+\", \"-\").lower()\n",
    "    label_text = f\"\\\\label{{tab:real-cost-mean-std-{data_set_slug}}}\"\n",
    "    \n",
    "    caption_text = f\"\\caption{{Costs of the evaluated algorithms on the {data_set_text}. Each cell specify the mean along with the standard deviation in parenthesis of 10 repetitions of the experiment.}}\"\n",
    "    output = output.replace(r\"\\end{tabular}\", f\"{caption_text}\\n{label_text}\\n\\\\end{{longtable}}\")\n",
    "    \n",
    "    for n in [10, 20, 30, 40, 50, 60, 80, 100]:\n",
    "        output = output.replace(f\"          \\\\\\\\\\n{n} \", f\"\\\\\\\\\\n \\\\midrule\\n{n} \")\n",
    "    \n",
    "    # Remove empty lines\n",
    "    output = output.replace(\"\\n\\n\", \"\\n\")\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36295897-0f08-406f-862c-8e067b45b2e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5a4fb2b-60a8-432b-a7cb-3cde8d7e321e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate Distortion Tables in LaTex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e03821-00b0-4949-b6cf-e4aa6bf57404",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Distortion Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01561e90-0a29-4f41-afc9-67e6c271bad7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "add_combined_mean_std(df=df_aggr_costs, attr=\"distortion\")\n",
    "\n",
    "df_results_table = pd.pivot_table(\n",
    "    data=df_aggr_costs,\n",
    "    values=\"distortion_mean_std\",\n",
    "    index=[\"dataset\", \"k\", \"coreset_size_factor\"],\n",
    "    columns=[\"algorithm\"],\n",
    "    aggfunc=lambda x: ' '.join(x)\n",
    ")\n",
    "\n",
    "data_sets = sorted(list(set([keys[0] for keys in df_results_table.index])))\n",
    "\n",
    "\n",
    "tables_text = \"\"\n",
    "for i, data_set in enumerate(data_sets):\n",
    "    data_set_slug = data_set.replace(\"+\", \"-\").lower()\n",
    "    if i > 0:\n",
    "        tables_text += \",\\n \"\n",
    "    label_text = f\"\\\\cref{{tab:distortions-mean-std-{data_set_slug}}}\"\n",
    "    tables_text += label_text\n",
    "    \n",
    "print(f\"The tables \\n({tables_text})\\n show the distortions of the 5 evaluated algorithms on the different data sets.\")\n",
    "print(f\"We vary the coreset size $T$ for different $k$ values using the formula: $T=mk$ where $m = \\\\{{50, 100, 200, 500\\\\}}$.\")\n",
    "print(f\"The running time for StreamKM++ with coreset size $T=500k$ exceeds the allocated time budget of 12 hours on almost all data sets.\")\n",
    "print(\"For this reason, the distortions for StreamKM++ with $m=500$ are excluded.\")\n",
    "print(f\"\\n\\n\")\n",
    "    \n",
    "for data_set in data_sets:\n",
    "    data_set_without_pca = data_set.replace(\"+PCA\", \"\")\n",
    "    pca_tag = \" (with PCA preprocessing)\" if \"PCA\" in data_set else \"\"\n",
    "    data_set_text = f\"\\\\textit{{{data_set_without_pca}}} data set{pca_tag}\"\n",
    "    \n",
    "    top_text = r\"\\multicolumn{7}{c}{\\textbf{Distortions on the \" + data_set_text + r\"}} \\\\\"\n",
    "    \n",
    "    output = df_results_table.loc[data_set].to_latex()\n",
    "    output = output.replace(r\"\\begin{tabular}{lllllll}\", r\"\\begin{longtable}{lllllll}\" + \"\\n\" +top_text)\n",
    "    output = output.replace(r\"& algorithm &\", r\"&  &\")\n",
    "    output = output.replace(r\"k & coreset\\_size\\_factor &               &                &               &                      &               \\\\\", \"\")\n",
    "    output = output.replace(r\"k & coreset\\_size\\_factor &                &                &                &                      &               \\\\\", \"\")\n",
    "    output = output.replace(r\"   &  &          \", r\"k & m &\")\n",
    "    output = output.replace(r\"k &\", r\"\\parbox[t]{10mm}{\\ \\\\$k$} &\")\n",
    "    output = output.replace(r\"m &\", r\"\\parbox[t]{10mm}{\\ \\\\$m$} &\")\n",
    "    \n",
    "    output = output.replace(r\"Group Sampling\", r\"\\parbox[t]{1cm}{Group\\\\Sampling}\")\n",
    "    output = output.replace(r\"     Ray Maker \", r\"\\parbox[t]{1cm}{Ray\\\\Maker}\")\n",
    "    output = output.replace(r\" Sensitivity Sampling \", r\"\\parbox[t]{1cm}{Sensitivity\\\\Sampling}\")\n",
    "    \n",
    "    output = output.replace(r\"NaN\", r\"\")\n",
    "    data_set_slug = data_set.replace(\"+\", \"-\").lower()\n",
    "    label_text = f\"\\\\label{{tab:distortions-mean-std-{data_set_slug}}}\"\n",
    "    \n",
    "    caption_text = f\"\\caption{{Distortions of the evaluated algorithms on the {data_set_text}. Each cell specify the mean distortion along with the standard deviation in parenthesis of 10 repetitions of the experiment.}}\"\n",
    "    output = output.replace(r\"\\end{tabular}\", f\"{caption_text}\\n{label_text}\\n\\\\end{{longtable}}\")\n",
    "    \n",
    "    for n in [10, 20, 30, 40, 50, 60, 80, 100]:\n",
    "        output = output.replace(f\"          \\\\\\\\\\n{n} \", f\"\\\\\\\\\\n \\\\midrule\\n{n} \")\n",
    "    \n",
    "    # Remove empty lines\n",
    "    output = output.replace(\"\\n\\n\", \"\\n\")\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7301ff6-b0e6-4570-8306-8c64e2b0209e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Solution Generation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008f165-7b72-4f46-9a19-298acf30dd5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Candidate Solution Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1155be-944f-4bca-ad49-f1d86acb0d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = \"Caltech\"\n",
    "algorithm_name = \"BICO\"\n",
    "df_filtered = df_aggr_costs[(df_aggr_costs.dataset == data_set) & (df_aggr_costs.algorithm == algorithm_name)]\n",
    "df_filtered = df_filtered.rename(columns={\n",
    "    \"coreset_size_factor\": \"m\",\n",
    "    \"distortion_mean_std\": \"k-means++\",\n",
    "    \"distortion_synthetic2_mean_std\": \"Random CH\",\n",
    "    \"distortion_synthetic_mean_std\": \"Random MEB\",\n",
    "})\n",
    "#df_filtered = df_filtered.groupby([\"dataset\", \"algorithm\", \"k\"]).count()\n",
    "cols = [\"k\", \"m\", \"k-means++\", \"Random CH\", \"Random MEB\"]\n",
    "\n",
    "output = df_filtered[cols].to_latex(index=False)\n",
    "\n",
    "data_set_without_pca = data_set.replace(\"+PCA\", \"\")\n",
    "pca_tag = \" (with PCA preprocessing)\" if \"PCA\" in data_set else \"\"\n",
    "data_set_text = f\"\\\\textit{{{data_set_without_pca}}} data set{pca_tag}\"\n",
    "top_text = r\"\\multicolumn{5}{c}{\\textbf{Distortions of \"+algorithm_name+\" on the \"+data_set_text+r\"}} \\\\\"\n",
    "\n",
    "\n",
    "output = output.replace(r\"\\begin{tabular}{rrlll}\", r\"\\begin{longtable}{rrlll}\" + \"\\n\" + top_text)\n",
    "\n",
    "output = re.sub(r\"^(\\d0) &  \", r\"\\1  &  \", output, flags=re.MULTILINE)\n",
    "output = re.sub(r\"^(\\d{2}) & \", r\"    & \", output, flags=re.MULTILINE)\n",
    "\n",
    "output = re.sub(r\"\\\\\\\\$(\\n\\d{2})\", r\"\\\\\\\\\\n\\\\midrule\\1\", output, flags=re.MULTILINE)\n",
    "\n",
    "\n",
    "output = output.replace(\"k \", \"$k$ \")\n",
    "output = output.replace(\"k-\", \"$k$-\")\n",
    "output = output.replace(\" m \", \" $m$ \")\n",
    "\n",
    "caption_text = \"\"\"\\caption{The effect of different solution generation approaches on the distortions (see \\cref{sec:candidate-solution-generation}).\n",
    "The distortions are obtained by running BICO on the \\\\textit{Caltech} data set.\n",
    "}\"\"\"\n",
    "\n",
    "\n",
    "label_postfix = f\"{data_set.lower()}-{algorithm_name.lower()}\"\n",
    "end_texts = [\n",
    "    caption_text,\n",
    "    r\"\\label{tab:comparison-solution-generation-\"+label_postfix+\"}\",\n",
    "    r\"\\end{longtable}\",\n",
    "]\n",
    "\n",
    "output = output.replace(r\"\\end{tabular}\", \"\\n\".join(end_texts))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2f2414-605d-453b-a45c-a5eee4128260",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Comparing Solution Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fbc90b-3997-4320-b198-2188ade1104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_aggr_costs[df_aggr_costs.dataset.isin([\"Benchmark\", \"NYTimes+PCA\"]) == False].copy()\n",
    "df_filtered = df_filtered.rename(columns={\n",
    "    \"coreset_size_factor\": \"m\",\n",
    "    \"distortion_mean\": \"KM\",\n",
    "    \"distortion_synthetic2_mean\": \"CH\",\n",
    "    \"distortion_synthetic_mean\": \"MEB\",\n",
    "})\n",
    "cols = [\"dataset\", \"algorithm\", \"k\", \"m\", \"KM\", \"CH\", \"MEB\"]\n",
    "df_filtered = df_filtered[cols]\n",
    "\n",
    "df_max_distortions = df_filtered.groupby([\"dataset\", \"algorithm\"])[[\"KM\", \"CH\", \"MEB\"]].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6523a897-32f3-446c-80c8-90d5113ef21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = df_max_distortions.to_latex()\n",
    "\n",
    "output = output.replace(r\"\\begin{tabular}{llrrr}\", r\"\\begin{longtable}{llrrr}\")\n",
    "\n",
    "output = output.replace(r\"      &            &         KM &         CH &        MEB \\\\\", r\" Data set  & Algorithm     &         KM &         CH &        MEB \\\\\")\n",
    "output = output.replace(r\"dataset & algorithm &            &            &            \\\\\", r\"\")\n",
    "output = output.replace(r\" KM \", r\"$k$-means++\")\n",
    "output = output.replace(r\" CH \", r\"Random CH\")\n",
    "output = output.replace(r\" MEB \", r\"Random MEB\")\n",
    "# output = output.replace(r\"\", r\"\")\n",
    "\n",
    "# output = output.replace(r\"\", r\"\")\n",
    "\n",
    "\n",
    "output = re.sub(r\"( \\\\\\\\\\n)([A-Z])\", r\"\\1\\\\midrule\\n\\2\", output, flags=re.MULTILINE)\n",
    "\n",
    "caption_text = \"\"\"\\caption{The effect of different solution generation approaches on the distortions (see \\cref{sec:evaluation-procedure}).\n",
    "The distortions are aggregated across different algorithms and data sets.\n",
    "}\"\"\"\n",
    "\n",
    "end_texts = [\n",
    "    caption_text,\n",
    "    r\"\\label{tab:comparison-solution-generation-all}\",\n",
    "    r\"\\end{longtable}\",\n",
    "]\n",
    "\n",
    "output = output.replace(r\"\\end{tabular}\", \"\\n\".join(end_texts))\n",
    "\n",
    "# Remove empty lines\n",
    "output = output.replace(\"\\n\\n\", \"\\n\")\n",
    "    \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b3711c-b34a-48a8-bbe9-6942ef7a53d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
